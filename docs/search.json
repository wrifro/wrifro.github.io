[
  {
    "objectID": "posts/Blog_2/Untitled.html",
    "href": "posts/Blog_2/Untitled.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "LR = LogisticRegression()\n\nLR.fit(X,y,0.01,2000)\n\nX_ = np.append(X, np.ones((X.shape[0], 1)), 1)\n\n\nw = LR.w\n\nloss = LR.empirical_risk(X_, y, LR.loss, w)\n\nfig, axarr = plt.subplots(1, 2)\n\naxarr[0].scatter(X[:,0], X[:,1], c = y)\naxarr[0].set(xlabel = \"Feature 1\", ylabel = \"Feature 2\", title = f\"Loss = {loss}\")\n\nf1 = np.linspace(-3, 3, 101)\n\np = axarr[0].plot(f1, (w[2] - f1*w[0])/w[1], color = \"black\")\n\naxarr[1].plot(LR.loss_history)\naxarr[1].set(xlabel = \"Iteration number\", ylabel = \"Empirical Risk\")\nplt.tight_layout()\n\n\n\n\n\nLR.score_history\n\n[0.61,\n 0.62,\n 0.64,\n 0.64,\n 0.64,\n 0.68,\n 0.68,\n 0.68,\n 0.69,\n 0.69,\n 0.69,\n 0.7,\n 0.71,\n 0.72,\n 0.73,\n 0.73,\n 0.74,\n 0.75,\n 0.77,\n 0.77,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.81,\n 0.81,\n 0.81,\n 0.81,\n 0.82,\n 0.82,\n 0.82,\n 0.82,\n 0.82,\n 0.82,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83]"
  },
  {
    "objectID": "posts/Blog_2/GradientDescentBlog.html",
    "href": "posts/Blog_2/GradientDescentBlog.html",
    "title": "Gradient Descent Blog",
    "section": "",
    "text": "Gradient descent takes advantage of convexity to minimize empirical risk for a function. Much like the perceptron algorithm, the goal of the experiments in this blog post is to find the best line dividing two sets of points; unlike perceptron, these points may not be linearly separable. So, what advantage does gradient descent offer? If our loss function is convex, we know that we can use gradient descent to find the local minimum of the function, and therefore find the optimal line dividing our two sets of points. This line will not perfectly divide the two sets of points, but we know that it is the best possible line because we have minimized the loss. That’s the theory behind all of this… let’s dive into the implementation.\n\n\nThis is simlar to the Perceptron blog: generating two clouds of points, except this time they are NOT linearly separable.\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom LogisticRegression import LogisticRegression\nfrom matplotlib import pyplot as plt\nfrom sklearn.datasets import make_blobs\nnp.seterr(all='ignore')\n\np_features = 3\n\nX, y = make_blobs(n_samples = 100, n_features = p_features - 1, centers = [(-1, -1), (1, 1)])\nX_ = np.append(X, np.ones((X.shape[0], 1)), 1)\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\n\n\n\nWe can fit a logistic regression model using regular gradient descent. This is a no frills approach – we are considering every point, calculating a new gradient for empirical risk based on the performance of the current weight vector, and, once empirical risk is minimized, the function is considered to be optimized.\n\nLR = LogisticRegression()\n\nLR.fit(X,y,alpha = 0.01,m_epochs = 10000)\n\nconverged\n\n\n\n\n\nw = LR.w\n\nloss = LR.empirical_risk(X_, y, LR.loss, w)\n\nfig, axarr = plt.subplots(1, 2)\n\naxarr[0].scatter(X[:,0], X[:,1], c = y)\naxarr[0].set(xlabel = \"Feature 1\", ylabel = \"Feature 2\", title = f\"Loss = {loss}\")\n\nf1 = np.linspace(-3, 3, 101)\n\np = axarr[0].plot(f1, (w[2] - f1*w[0])/w[1], color = \"black\")\n\naxarr[1].plot(LR.loss_history)\naxarr[1].set(xlabel = \"Iteration number\", ylabel = \"Empirical Risk\")\nplt.tight_layout()\n\nAttributeError: 'LogisticRegression' object has no attribute 'empirical_risk'\n\n\nThis function does pretty well! 14.7% empirical risk is a pretty good performance, and visually, the line fits what we might expect. We can see in the plot on the right that the loss moved rapidly to a good solution but took a while to fully minimize.\n\n\n\n\nStochastic descent is like regular gradient descent, but weight is updated for a subset of points at a time rather than for all points.\nThe batch_size argument denotes how large the subset of points used for weight updates is.\n\nLR2 = LogisticRegression()\n\nLR2.fit_stochastic(X,y,10000,alpha=0.01,batch_size = 20) \n\nconverged\n\n\n\nw2 = LR2.w\n\nloss2 = LR2.loss(X_, y,w2)\n\nfig, axarr = plt.subplots(1, 2)\n\naxarr[0].scatter(X[:,0], X[:,1], c = y)\naxarr[0].set(xlabel = \"Feature 1\", ylabel = \"Feature 2\", title = f\"Loss = {loss2}\")\n\nf1 = np.linspace(-3, 3, 101)\n\np = axarr[0].plot(f1, (w2[2] - f1*w2[0])/w2[1], color = \"black\")\n\naxarr[1].plot(LR2.loss_history)\naxarr[1].set(xlabel = \"Iteration number\", ylabel = \"Empirical Risk\")\naxarr[1].legend([\"Stochastic Grad Desc\"])\nplt.tight_layout()\n\n\n\n\nIt worked as well! Actually, it worked even better than the regular gradient descent algorithm – the weights are very similar but stochastic gradient descent turns out just a slightly improved weight vector. I don’t know if this is a bug in my code and if this is actually slightly better than what is achievable; clearly this is not an unreasonable weight vector but it is odd that it is consistently just a little bit better than the regular gradient descent method.\nWith that said, we can still see how quickly stochastic gradient descent works. It’s important to note that each iteration here corresponds to an epoch, not to an individual weight update. There may be many weight updates in a single epoch. But by splitting points up into batches, we can ensure that each epoch really is a marked improvement over the one that came before.\n\n\n\nSo far, we’ve worked with alpha = 0.01. This is a small but reasonable learning rate. But what if it’s bigger?\n\nLR.fit(X,y,alpha = 5,m_epochs = 10000)\n\nconverged\n\n\nConverges with alpha = 5…\n\nLR.fit(X,y,alpha = 100, m_epochs = 20000)\n\nconverged\n\n\nConverges with alpha = 100, but we need many more epochs…\n\nLR.fit(X,y,alpha = 10000, m_epochs = 100000)\n\nDoesn’t converge with alpha = 10,000 and 100,000 epochs.\nLet’s dive into the loss history of this iteration of the Logistic Regression fit method.\n\nw3 = LR.w\n\nfig, axarr = plt.subplots(1, 2)\n\naxarr[0].scatter(X[:,0], X[:,1], c = y)\naxarr[0].set(xlabel = \"Feature 1\", ylabel = \"Feature 2\", title = f\"Loss = {loss3}\")\n\nf1 = np.linspace(-3, 3, 101)\n\np = axarr[0].plot(f1, (w3[2] - f1*w3[0])/w3[1], color = \"black\")\n\naxarr[1].plot(LR.loss_history)\naxarr[1].set(xlabel = \"Iteration number\", ylabel = \"Empirical Risk\")\naxarr[1].legend([\"Stochastic Grad Desc\"])\nplt.tight_layout()\n\n\n\n\nThat doesn’t look good! It looks like we start out descending as we should, but then things look a little bit funky.\nLet’s dive into the loss history to see what happens here.\n\nLR.loss_history[6000:7000:100]\n\n[0.14742965239913441,\n 0.147269892933168,\n 0.14711595665205013,\n 0.14202729291257218,\n 0.1474466655245315,\n nan,\n nan,\n 0.1740478913069895,\n nan,\n 0.18211801679248396]\n\n\nHere we go. At about the 500th iteration, we our value suddenly stops descending and starts to rise rapidly. This is because our learning rate is so large that we overshot the minimum of the function, and our gradient starts GROWING instead of minimizing.\n\n\n\nHow does batch_size influence the speed of the fit_stochastic method?\nLet’s explore this using a more complex set of points, with twelve feature dimensions.\n\np = 11\n\nX1, y1 = make_blobs(n_samples = 100, n_features = p - 1,centers = 2)\nX1_ = np.append(X, np.ones((X.shape[0], 1)), 1)\n\n\nprint(X1[0], X1.shape)\n\n[ 2.31724415 -6.12119258 -6.56044559  5.94031272 -6.62189465 -0.6047373\n -1.65291106 -6.4506718   7.16439231  9.82855518] (100, 10)\n\n\nOkay, now we have 100 different points with 12 features each. Let’s try our algorithm on this set of points.\n\nLR3 = LogisticRegression()\n\nLR3.fit_stochastic(X1,y1,alpha = 0.001, m_epochs = 20000, batch_size = 50)\n# Since batch size is 10, that means there will be ten batches in each epoch (100 points / batch size 10 = 10 batches)\n\nconverged\n\n\nIt converged! In how many steps?\n\nlen(LR3.loss_history)\n\n10046\n\n\nLet’s try divvying the batches more. With a batch size of 50 and 100 points, there are only 2 batches per epoch.\n\nLR3.fit_stochastic(X1,y1,alpha = 0.001, m_epochs = 20000, batch_size = 25)\n\nconverged\n\n\n\nlen(LR3.loss_history)\n\n17562\n\n\nTook longer than before.\n\nLR3.fit_stochastic(X1,y1,alpha = 0.001, m_epochs = 20000, batch_size = 10)\n\nconverged\n\n\n\nlen(LR3.loss_history)\n\n22708\n\n\nStarting to see a pretty clear pattern.\n\nLR3.fit_stochastic(X1,y1,alpha = 0.001, m_epochs = 20000, batch_size = 5)\n\nconverged\n\n\n\nlen(LR3.loss_history)\n\n26346\n\n\nIt is pretty clear after running these experiments that decreasing the batch size INCREASES the amount of time it takes to converge to a true solution. This may be because smaller batches make more room for volatility (the weight might move in the wrong direction) so even though the loss might reach a reasonable point quickly, it takes a while to truly converge.\n\n\n\nBoth the regular gradient descent and stochastic gradient descent are exciting and powerful. They do what the perceptron algorithm cannot, and find the best line if two sets of points are not linearly separable. They run on multiple dimensions, and are quite efficient even if not perfect. Given more time I would have loved to implement stochastic gradient with momentum, but didn’t quite have the time to make it even more efficient. Something for the future."
  },
  {
    "objectID": "posts/Blog_2/Gradient_Descent_Blog.html",
    "href": "posts/Blog_2/Gradient_Descent_Blog.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "LR = LogisticRegression()\n\nLR.fit(X,y,0.01,10000)\n\nX_ = np.append(X, np.ones((X.shape[0], 1)), 1)\n\nconverged\n\n\n\nw = LR.w\n\nloss = LR.empirical_risk(X_, y, LR.loss, w)\n\nfig, axarr = plt.subplots(1, 2)\n\naxarr[0].scatter(X[:,0], X[:,1], c = y)\naxarr[0].set(xlabel = \"Feature 1\", ylabel = \"Feature 2\", title = f\"Loss = {loss}\")\n\nf1 = np.linspace(-3, 3, 101)\n\np = axarr[0].plot(f1, (w[2] - f1*w[0])/w[1], color = \"black\")\n\naxarr[1].plot(LR.loss_history)\naxarr[1].set(xlabel = \"Iteration number\", ylabel = \"Empirical Risk\")\nplt.tight_layout()\n\n\n\n\n\nLR.score_history\n\n[0.61,\n 0.62,\n 0.64,\n 0.64,\n 0.64,\n 0.68,\n 0.68,\n 0.68,\n 0.69,\n 0.69,\n 0.69,\n 0.7,\n 0.71,\n 0.72,\n 0.73,\n 0.73,\n 0.74,\n 0.75,\n 0.77,\n 0.77,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.78,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.79,\n 0.81,\n 0.81,\n 0.81,\n 0.81,\n 0.82,\n 0.82,\n 0.82,\n 0.82,\n 0.82,\n 0.82,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83,\n 0.83]"
  },
  {
    "objectID": "posts/example-blog-post/firstPost.html",
    "href": "posts/example-blog-post/firstPost.html",
    "title": "Intro blog post",
    "section": "",
    "text": "And now I’ll try adding it in markdown:\ndef addTwoNumbers(num_a, num_b):\n    sum = num_a + num_b\n    return sum\naddTwoNumbers(3,5)\nLet’s see if this post works…"
  },
  {
    "objectID": "posts/example-blog-post/index.html",
    "href": "posts/example-blog-post/index.html",
    "title": "Hello Blog",
    "section": "",
    "text": "This is an example of the blog posts that you’ll submit as your primary form of learning demonstration in CSCI 0451. I created this post by modifying the file posts/example-blog-post/index.ipynb in VSCode. You can also use JupyterLab for this editing if you prefer. Finally, it is possible to write blog posts without using notebooks by writing .qmd files, as illustrated here."
  },
  {
    "objectID": "posts/example-blog-post/index.html#math",
    "href": "posts/example-blog-post/index.html#math",
    "title": "Hello Blog",
    "section": "Math",
    "text": "Math\nIn addition to regular text using the Markdown specification, you can also write mathematics, enclosed between dollar signs. The syntax for writing math is very similar to the syntax used in the \\(\\LaTeX\\) markup language. For example, $f(x) \\approx y$ renders to \\(f(x) \\approx y\\). To place complex mathematical expressions on their own lines, use double dollar signs. For example, the expression\n$$\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2$$\nrenders to:\n\\[\\mathcal{L}(a, b) = \\sum_{i = 1}^n (ax_i + b - y_i)^2\\;.\\]\nBehind the scenes, math is powered by the MathJax engine. For more on how to write math, check this handy tutorial and quick reference.\n---\ntitle: Intro blog post\nauthor: Wright Frost\ndate: '2023-02-16'\ndescription: 'Just playing around with markdown and quarto'\nformat: html\n---\n\n\n\nI’m going to add some python code:\ndef addTwoNumbers(num_a, num_b):\n    sum = num_a + num_b\n    return sum\naddTwoNumbers(3,5)\n```\n\n\n\nWill this work and make a new post? Not sure. Hopefully yes.\nAnyway….. my name is Wright, I’m a Computer Science and Geography Double major, and this is my attempt at a blog post!"
  },
  {
    "objectID": "posts/Blog_1/Untitled1.html",
    "href": "posts/Blog_1/Untitled1.html",
    "title": "My Awesome CSCI 0451 Blog",
    "section": "",
    "text": "def gradient(w1,w2):\n    (w2 * np.cos(w1 * w2),w1 * np.cos(w1 * w2))"
  },
  {
    "objectID": "posts/Blog_1/PerceptronBlog.html",
    "href": "posts/Blog_1/PerceptronBlog.html",
    "title": "Perceptron Blog",
    "section": "",
    "text": "Perceptron source code: click here"
  },
  {
    "objectID": "posts/Blog_1/PerceptronBlog.html#how-does-the-perceptron-algorithm-work",
    "href": "posts/Blog_1/PerceptronBlog.html#how-does-the-perceptron-algorithm-work",
    "title": "Perceptron Blog",
    "section": "How does the perceptron algorithm work?",
    "text": "How does the perceptron algorithm work?\nThe key part of the perceptron algorithm is the update step. In my code, this is done in both the fit and update methods.\nMathematically, this can be represented as: (on a personal note this is the first thing I have ever done in LaTeX and I’m really proud of it)\n\\(\\hat{w}^{(t+1)} = \\hat{w}^t + \\mathbb{1}(\\tilde{y}_i(\\vec{\\hat{w}^t} \\cdot \\vec{\\tilde{x}_1}) <0){\\tilde{y}_i} {\\tilde{x}_1}\\)\nWithin the fit() method, this is done in the following code:\ny_hat = np.dot(w,X_i)\nw_i = ( (np.multiply(y_hat, y_i) >= 0) * w_i)  + ( (np.multiply(y_hat, y_i) < 0) * (w_i + np.multiply(y_i,X_i)) )\nThe logic is actually fairly simple. Y_hat represents the predicted score for X_i, the current index/value being considered. If y_hat is correctly classified, multiplying it by y_i should yield True, equal to 1 in Python. The other part of the equation checks to see if this product is less than 1 (using 1s and -1s instead of 1s and 0s for our y values makes this possible). If it is, this expression will evaluate to True, which is equal to 1 in Python.\nOnly one of these expressions is true at any given time. When False, these evaluate to zero.\nIf the first expression is True, aka when it is equivalent to 1, it preserves the current weight vector, while the second expression, equal to zero, nullifies its coefficient.\nWhen the second expression is True and therefore equal to 1, it is multiplied by the sum of w_i (the current weight vector) and the product of the feature matrix (X) at index i, and the classification matrix (y) at index i. This sounds complicated, but really this line of code is just either keeping the old weight vector if it classified point i correctly, or adding or subtracting the value it incorrectly classified to ensure that it classifies it correctly in the next iteration.\nThis logic is the same in the update method. The only difference is that update accepts a weight vector as a parameter, running only a single step of the Perceptron algorithm rather than to completion."
  },
  {
    "objectID": "posts/Blog_1/PerceptronBlog.html#if-the-data-are-linearly-separable-then-the-perceptron-algorithm-will-converge.",
    "href": "posts/Blog_1/PerceptronBlog.html#if-the-data-are-linearly-separable-then-the-perceptron-algorithm-will-converge.",
    "title": "Perceptron Blog",
    "section": "If the data are linearly separable, then the perceptron algorithm will converge.",
    "text": "If the data are linearly separable, then the perceptron algorithm will converge.\nLet’s vizualise the process of improvement by showing the progression of the Perceptron algorithm over time.\n\nfig = plt.scatter(X[:,0], X[:,1], c = y)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\np2 = Perceptron()\n\n\n\n\n\nLet’s see how the algorithm updates over time…\nThese three plots only show instances where the weight vector updates (that is to say, when the algorithm misclassifies a point and updates the weight vector to reflect this). This ensures that we actually see how the Perceptron algorithm corrects itself over time. Otherwise, we might just see three cases where it correctly classifies a point and nothing changes. BORING!!!\n\nw_next = np.random.rand(p_features)\n\nplt.rcParams[\"figure.figsize\"] = (8, 4)\nfig, axarr = plt.subplots(1, 3, sharex = True, sharey = True)\nX_1 = np.append(X, np.ones((X.shape[0], 1)), 1)\nscore_prev = 0\n\nfor ax in axarr.ravel():\n    ax.set(xlim = (-5, 5), ylim = (-5, 5))\n    w_prev = w_next\n    ax.scatter(X[:,0],X[:,1], c = y)\n    draw_line(w_prev, -10, 10,ax,linestyle = \"dashed\") \n    done = False\n    while done == False:\n        w_next, score, i = p2.update(X,y,w_prev)\n        if (score_prev != score) or score == 1 :\n            done = True\n    score_prev = score\n    draw_line(w_next, -10, 10,ax)\n    ax.scatter(X[i, 0], X[i, 1],color = \"none\", facecolors = \"none\", edgecolors = \"red\")\n    accuracy = (score)\n    ax.set_title(f\"accuracy = {accuracy}\")\n    \nplt.tight_layout()\n\n\n\n\nIt is fairly easy to see that the algorithm updates when it missclassifies a point, gradually improving until it achieves convergence.\n\n\nWhat if the data are not linearly separable?\nLet’s repeat the same experiment as above, only this time, using two clouds of points that are NOT linearly separable.\nWe can achieve this easily with the make_blobs function by making the centers closer to one another.\n\nX2, y2 = make_blobs(n_samples = 100, n_features = p_features - 1, centers = [(-1.7, -1.3), (1.7,0.3)])\n\nfig = plt.scatter(X2[:,0], X2[:,1], c = y2)\nxlab = plt.xlabel(\"Feature 1\")\nylab = plt.ylabel(\"Feature 2\")\n\n\n\n\n\nplt.rcParams[\"figure.figsize\"] = (8, 6)\nfig1, axarr1 = plt.subplots(2, 3, sharex = True, sharey = True)\n\nw_next1 = np.random.rand(p_features)\n\nscore_1 = 0\n\nfor ax in axarr1.ravel():\n    ax.set(xlim = (-5, 5), ylim = (-5, 5))\n    w_prev1 = w_next1\n    ax.scatter(X2[:,0],X2[:,1], c = y2)\n    draw_line(w_prev1, -10, 10,ax,linestyle = \"dashed\") \n    done = False\n    while done == False:\n        score_prev = score1\n        w_next1,score1,i = p2.update(X2,y2,w_prev1)\n        if (score_prev != score1) or score1 == 1 :\n            done = True\n    draw_line(w_next1, -10, 10,ax)\n    ax.scatter(X2[i, 0], X2[i, 1],color = \"none\", facecolors = \"none\", edgecolors = \"red\")\n    accuracy = (score1)\n    ax.set_title(f\"accuracy = {accuracy}\")\n    \nplt.tight_layout()\n\n\n\n\nWe can see that the algorithm still updates and tries to correct itself, but is unable to achieve 100% accuracy. Including more subplots helps to show that this process of guessing but never achieving convergence will continue infinitely.\n\n\nCan Perceptron work in more than 2 dimensions?\nOnly one way to find out…\nLet’s start by generating a 5D feature matrix.\n\nX5d = np.random.rand(100,5)\ny5d = np.random.choice([0, 1], size=100)\n\nWe now have a random 5d feature matrix, and a random binary classification for each point.\nLet’s try to run it with 10,000 max steps…\n\np3 = Perceptron()\n\np3.fit(X5d,y5d, max_steps = 10000)\n\nDid it work?\n\np3.score(X5d,2*y5d-1)\n\n0.6\n\n\nIt works! It makes sense that it wouldn’t achieve convergence on a completely random set of points and classifications.\nIt is worth asking, though, is it theoretically possible to have a linearly separable set of points in 5 (or more) dimensions?\nIt is pretty straightforward to see that this is possible in 3 dimensions - imagine a flat plane separating 2 clouds of points in 3 dimensions.\nIn 5 dimensions, all that this means is that the weight vector multiplied by the feature matrix correctly classifies each point – either one or zero. One does not need to imagine what a 5D physical space might look like to see that this is certainly achievable.\n\n\nPerceptron Runtime\nFinally, let’s consider the question of how long it takes for the update step to run.\nWhat is actually happening? Just multiplication and some logical comparisons, really – we check to see if mathematically the product of our weight vector and the feature matrix evaluates to what we would expect it to be, and if not, we perform some simple matrix multiplication and addition to get our new weight vector. This is dependent on the number of features (p), but not on the number of points (n). Therefore, this operation takes O(p) time. It does not matter how many points there are, because we are only focusing on a single data point at a time, and updating only relative to that point. So the only variable impacting the time complexity of this operation is p – the number of features."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Wright’s CS0451 Blog",
    "section": "",
    "text": "Implementing and Exploring the Perceptron Algorithm\n\n\n\n\n\n\nMar 10, 2023\n\n\nWright Frost\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImplementing and Exploring the Perceptron Algorithm\n\n\n\n\n\n\nFeb 28, 2023\n\n\nWright Frost\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJust playing around with markdown and quarto\n\n\n\n\n\n\nFeb 16, 2023\n\n\nWright Frost\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\nAn example blog post illustrating the key techniques you’ll need to demonstrate your learning in CSCI 0451.\n\n\n\n\n\n\nJan 10, 2023\n\n\nPhil Chodrow\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]