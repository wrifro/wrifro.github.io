{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e91dce6f-a570-4845-9f6f-3aee2c16569f",
   "metadata": {},
   "source": [
    "---\n",
    "title: Learning from Timnit Gebru\n",
    "author: Wright Frost\n",
    "date: '2023-04-19'\n",
    "description: 'Dr. Timnit Gebru comes to Middlebury!'\n",
    "format: html\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fdbfe9-e2c4-4c82-a9c8-365fee747f65",
   "metadata": {},
   "source": [
    "# Dr. Timnit Gebru comes to Middlebury\n",
    "\n",
    "On Monday, Apr 24, Dr. Timnit Gebru is coming to Middlebury to give a talk on Computer Vision and \"Artificial General Intelligence.\" Dr. Gebru is one of the leading voices on the ethics and impacts of AI. Motivated by her own experiences with race- and gender-based discrimination, she has undertaken projects looking at things like the reliability (or lack thereof) of facial recognition software to identify Black women. She is also a strong advocate for accountability for Big Tech, and in 2020 was fired from her then-job at Google after the company tried to prevent her from publishing a paper on the dangers of AI language models. Since then, she has focused on independent research to improve public knowledge of the risks and biases of AI. She is a brave and outspoken voice in her field, and is inspiring because of her tumultuous upbringing – she immigrated to the US seeking asylum from war in her home country – and her breaking-down of gender and racial barriers in a famously insular industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4224ff-4947-4e42-b6a3-b36e4ef67e15",
   "metadata": {},
   "source": [
    "### Fairness, Accountability, Transparency, and Ethics in Computer Vision\n",
    "It is pretty widely accepted that issues with AI recognition softwares such as algorithms trained to identify the gender of a subject in an image, are hindered by the datasets they are trained on, and that they are trained with a bias towards white men. But Dr. Gebru points out in her talk on Fairness, Accountability, Transparency, and Ethics in Computer Vision, that datasets are a secondary issue. The real issue, she claims, is that these technologies exist in the first place. Black women are the group worst classified by gender recognition models, but race and gender are both social constructs, so as Dr. Gebru points out, gender recognition models are based on a flawed assumption. She also notes that facial recognition is not a purely objective tool since its purpose is often to identify and prosecute minority groups. Mass surveilance has made it easier than ever to discriminate against racial minorities and other marginalized groups. Her point is that the training data is only a small part of the issue with such technologies. The larger issue is why they exist in the first place, and what they are used for.\n",
    "#### tl;dr\n",
    "The data facial recognition models are trained on is only a small part of the issue with them; the greater issue is the application of these models as a way of targeting minorities and marginalized groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33917720-3c2f-4de4-99e1-ab5f9e434ac2",
   "metadata": {},
   "source": [
    "### Question(s) for Dr. Gebru\n",
    "1. Are there ways in which facial recognition software can be made inherently less biased? Or do its *applications* need to change for it to become a fairer technology?\n",
    "    - Tied into this, do you see any reasonable application for such software, or is it flawed at its core?\n",
    "2. What are some positive trends you see, if any, in AI/ML's objectivity and fairness towards marginalized groups?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdcffa4-24c2-4b8d-8d30-e0a5a4ad1002",
   "metadata": {},
   "source": [
    "___\n",
    "## Dr. Gebru's talk at Middlebury\n",
    "\n",
    "I am writing this some days after my initial thoughts written above. Two days ago, Dr. Gebru delivered her talk over Zoom to a full room of students, professors, and other interested parties. Her talk covered a lot of ground, and at times it was difficult to keep pace. I'm going to do my best to break down her argument.\n",
    "\n",
    "The first big items she addressed was AGI. AGI (Artificial General Intelligence) is a hypothetical higher form of AI, capable of matching or even exceeding the abilities of humans. She said it was akin to God; to me, it sounded more like the Matrix. In most discussions of AGI, people say that realizing it would lead to an apocalyptic event. Dr. Gebru said that people love sounding the alarm about AGI and the threats it poses, but that it is really pretty unlikely. In fact, her argument was more focused, from my perspective, on the threats of TRYING to achieve AGI rather than the threats it would pose if we were actually to achieve it. Tl;dr: AGI = God/The Matrix, but our biggest concerns aren't AGI itself. Rather, we should be concerned with the people trying to achieve it.\n",
    "\n",
    "The next part was partially a history lesson. Dr. Gebru gave some background on eugenics and its history in the US and abroad. She then explained what she called the \"TESCREAL bundle,\" TESCREAL being an acronym that stands for transhumanism, extropianism, singularitarianism, cosmism, rationalism, effective altruism, and longtermism. This part covered a lot of ground and moved very quickly, but her argument connected all of these movements as sharing the common goal of using technology to augment human health and capabilities to the point where, according to Dr. Gebru, they effectively create a new, superior, form of human. Now for the big claim: Dr. Gebru drew a straight line from the TESCREAL ideologies to first-wave eugenics. That is to say, she views Transhumanism, Extropianism, and the rest, as direct descendands of things like state-sponsored sterilization programs.\n",
    "\n",
    "I don't mean to be too critical, but I felt that this was a rushed portion of the talk. We were launched into a lot of definitions with little introduction, and Dr. Gebru didn't really complete this section of the talk, only giving about half of the definitions, out of order. This made it difficult for me to understand what the main point of her talk was supposed to be - especially because after giving this portion of the talk, she started down a different track, discussing how big tech is only concerned with profit, not with helping people. I couldn't figure out if this was her main argument for why proponents of TESCREAL ideologies are eugenicists, or a secondary argument.\n",
    "\n",
    "And then, rather without warning, her talk ended.\n",
    "\n",
    "Having not been given much of a conclusion during Dr. Gebru's talk, I am now left to try to figure out for myself what to make of it. I think there are three main points from her argument that I took away:\n",
    "\n",
    "1) People like to freak out about AGI/the singluarity/the AI apocalypse - but that is not where we should be focusing our energy.\n",
    "2) The parties currently trying to improve AI (like Sam Altman/OpenAI, Google, etc.) are practicing a modern form of eugenics.\n",
    "3) We should still improve AI, but we should promote a fairer balance of power by funding a more diverse range of voices and companies\n",
    "\n",
    "All three are very different points, each arguably big enough claims that they deserve their own talk. That's part of the reason that I am not totally convinced by Dr. Gebru's talk. Much of what she says I agree with, but I  can't say that I saw enough evidence to agree with her that, say, ChatGPT is equivalent to eugenics.\n",
    "\n",
    "With that said, I think she gets a lot right. Of course we need to represent a more diverse chorus of voices in Tech/AI/ML. I'm  glad she's a champion for that cause. I agree that people are probably alarmist about AGI. But I think the meat and potatoes of the talk - the TESCREAL bundle and eugenics - is an area I still feel undereducated on, and unconvinced by.\n",
    "\n",
    "With all of that said, this talk really got me thinking. I want to learn more. There are big problems with tech and with AI, and these problems demand our attention. Dr. Gebru's work is impressive and I'm glad I got the chance to see her talk. Perhaps it provided some people with clarity. But in truth, my main takeaway is a feeling of confusion. I'm motivated to learn more on my own, especially about movements like effective altruism that are oft-discussed but I feel like I don't fully understand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-0451]",
   "language": "python",
   "name": "conda-env-ml-0451-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
